{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WF8C0uFGZLtd"
      },
      "source": [
        "# **ENHANCE RAG WITH RE-RANKING**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CCOMFDsGZ2ty"
      },
      "source": [
        "### Extracting data from websites (Wikipedia web scraping)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ItU1I6WiK0Sf"
      },
      "outputs": [],
      "source": [
        "!apt-get install -y wkhtmltopdf\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kzcdSDCxL9Sq"
      },
      "outputs": [],
      "source": [
        "!pip install pdfkit\n",
        "!pip install requests\n",
        "!pip install beautifulsoup4\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZlbQYdYNs-SY",
        "outputId": "b3ebf17f-5a01-41a1-ff62-e07323e22fe8"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "import pdfkit\n",
        "\n",
        "# Function to scrape content from a given URL\n",
        "def scrape_content(url):\n",
        "    response = requests.get(url)\n",
        "    soup = BeautifulSoup(response.content, 'html.parser')\n",
        "    paragraphs = soup.find_all('p')\n",
        "    content = '\\n'.join([para.get_text() for para in paragraphs])\n",
        "    return content\n",
        "\n",
        "# Function to preprocess content by removing backslashes and unwanted spaces\n",
        "def preprocess_content(content):\n",
        "    content = content.replace('\\\\', '')\n",
        "    content = ' '.join(content.split())\n",
        "    return content\n",
        "\n",
        "urls = [\n",
        "    'https://en.wikipedia.org/wiki/Artificial_intelligence',\n",
        "    'https://en.wikipedia.org/wiki/Machine_learning',\n",
        "    'https://en.wikipedia.org/wiki/Deep_learning',\n",
        "    'https://en.wikipedia.org/wiki/Natural_language_processing',\n",
        "    'https://en.wikipedia.org/wiki/Image_processing',\n",
        "    'https://en.wikipedia.org/wiki/Computer_vision',\n",
        "    'https://en.wikipedia.org/wiki/Speech_recognition'\n",
        "]\n",
        "\n",
        "contents = [preprocess_content(scrape_content(url)) for url in urls]\n",
        "\n",
        "full_content = \"\\n\\n\".join(contents)\n",
        "\n",
        "with open('content.html', 'w') as file:\n",
        "    file.write(full_content)\n",
        "\n",
        "# Path to the installed wkhtmltopdf\n",
        "path_wkhtmltopdf = '/usr/bin/wkhtmltopdf'\n",
        "\n",
        "config = pdfkit.configuration(wkhtmltopdf=path_wkhtmltopdf)\n",
        "\n",
        "# Convert the HTML file to a PDF\n",
        "pdfkit.from_file('content.html', 'AI.pdf', configuration=config)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kMYKRm9ram4d"
      },
      "source": [
        "## **RAG Implementation**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AvJSxETgZdUr"
      },
      "source": [
        "To begin with install the required packages and import all the libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yC3q73MrppgW"
      },
      "outputs": [],
      "source": [
        "%pip install pypdf"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yssXOWWgppgZ"
      },
      "outputs": [],
      "source": [
        "%pip install langchain-chroma"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pfBo9K9BppgZ"
      },
      "outputs": [],
      "source": [
        "%pip install sentence_transformers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e_x7KvNUppga"
      },
      "outputs": [],
      "source": [
        "%pip install torch torchvision"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MJiXooBcscJh"
      },
      "outputs": [],
      "source": [
        "%pip install pinecone langchain openai"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rk-Wwm1EtdU_"
      },
      "outputs": [],
      "source": [
        "%pip install langchain_community"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JHGyEdfOu8HR"
      },
      "outputs": [],
      "source": [
        "%pip install langchain_openai"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "hiJXS7tJppga"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import time\n",
        "import getpass\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import pinecone\n",
        "from pinecone import Pinecone\n",
        "from langchain.text_splitter import CharacterTextSplitter\n",
        "from langchain.document_loaders import PyPDFLoader\n",
        "from langchain.embeddings import OpenAIEmbeddings\n",
        "from langchain.embeddings import HuggingFaceEmbeddings\n",
        "from langchain_community.vectorstores import LanceDB\n",
        "import openai"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "Q2f_8aJ9ppga"
      },
      "outputs": [],
      "source": [
        "from langchain_community.document_loaders import PyPDFLoader\n",
        "from langchain_openai import OpenAIEmbeddings\n",
        "\n",
        "loader = PyPDFLoader(r\"input file path\")\n",
        "pages = loader.load_and_split()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "id": "hVcGCgoUppga"
      },
      "outputs": [],
      "source": [
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "from transformers import AutoTokenizer\n",
        "\n",
        "text_splitter = RecursiveCharacterTextSplitter.from_huggingface_tokenizer(\n",
        "    tokenizer=AutoTokenizer.from_pretrained(\"sentence-transformers/all-MiniLM-L12-v2\"),\n",
        "    chunk_size=300,\n",
        "    chunk_overlap=100,\n",
        "    strip_whitespace=True,\n",
        ")\n",
        "docs = text_splitter.split_documents(pages)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "id": "kuvNexchppgb"
      },
      "outputs": [],
      "source": [
        "openai_api_key = 'your openai api key here'\n",
        "os.environ[\"OPENAI_API_KEY\"] = openai_api_key\n",
        "embeddings = OpenAIEmbeddings(model=\"text-embedding-3-large\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "id": "FzujUUauppgb"
      },
      "outputs": [],
      "source": [
        "from langchain_chroma import Chroma\n",
        "\n",
        "embedding = OpenAIEmbeddings()\n",
        "vectordb = Chroma.from_documents(documents=docs, embedding=embeddings)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OhwGG1Dqppgb"
      },
      "outputs": [],
      "source": [
        "def preprocess_content(content):\n",
        "    content = content.replace('\\\\', '')\n",
        "    content = ' '.join(content.split())\n",
        "    return content\n",
        "\n",
        "# Perform similarity search\n",
        "query = \"What is supervised learning?\"\n",
        "docsnew = vectordb.similarity_search(query)\n",
        "\n",
        "# Preprocess the retrieved content\n",
        "cleaned_content = preprocess_content(docsnew[0].page_content)\n",
        "cleaned_content"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6VGQsfAjppgb"
      },
      "outputs": [],
      "source": [
        "from sentence_transformers import CrossEncoder\n",
        "\n",
        "cross_encoder = CrossEncoder(\n",
        "    \"cross-encoder/ms-marco-TinyBERT-L-2-v2\", max_length=512, device=\"cpu\"\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MBIF6uqeppgc"
      },
      "outputs": [],
      "source": [
        "#cross encoder reranker\n",
        "from sentence_transformers import CrossEncoder\n",
        "cross_encoder = CrossEncoder('cross-encoder/ms-marco-MiniLM-L-6-v2')\n",
        "\n",
        "document_texts = [preprocess_content(doc.page_content) for doc in docsnew]\n",
        "\n",
        "response = [[query, doc_text] for doc_text in document_texts]\n",
        "\n",
        "scores = cross_encoder.predict(response)\n",
        "\n",
        "print(\"Scores:\")\n",
        "for score in scores:\n",
        "    print(score)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O_qbhIk5LdMu"
      },
      "outputs": [],
      "source": [
        "print(\"Responses:\")\n",
        "for res in response:\n",
        "    print(res[0], res[1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kyTnOe2Xye_G"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
